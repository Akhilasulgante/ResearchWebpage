<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Akhila Research Webpage</title>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Bai+Jamjuree:ital,wght@0,400;1,500&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;1,100;1,200;1,300&family=Rethink+Sans:ital,wght@0,400;1,400;1,600&display=swap"
      rel="stylesheet"
    />
    <link href="about.html" rel="import" />
  </head>
  <body>
    <canvas class="webgl"></canvas>
    <nav>
      <a href="/">ClarityLens</a>
      <ul>
        <li><a href="#aboutSection">About</a></li>
        <li>
          <a href="https://observablehq.com/d/3d39e1f333def77c" target="_"
            >Demo</a
          >
        </li>
        <li>
          <a href="https://www.overleaf.com/read/mhdvcxdkcvhw#6d5ce0" target="_"
            >Paper</a
          >
        </li>
      </ul>
    </nav>
    <h1 class="title">ClarityLens</h1>
    <p class="desc">See your Data and Model</p>
    <section id="aboutSection" style="padding-top: 40%">
      <h1 class="about_title">Project Overview</h1>
      <div class="about">
        <p class="about_desc">
          My primary objective was to empower users to identify and understand
          potential biases within the datasets, fostering transparency and
          accountability in machine learning processes. Through innovative
          visualization techniques, the tool provides a dynamic environment for
          users to navigate through diverse datasets, gaining insights into
          their data, and find co-relation between features. The tool will also
          enable users to understand all aspect of training and evaluating a
          model by authorizing complete control to users over the training
          features, train-train split and interpretation of evaluation matrix
          for bias detection.
        </p>

        <p class="about_desc">
          Bias in the ML dataset indicates prejudices and unfair inaccuracies in
          the data that is used to train ML models. In simple terms, certain
          groups of a dataset are overweighted or overrepresented. This bias can
          have a significant impact on the fairness of ML models. Beyond the
          technical challenges of ML models producing inaccurate results, their
          implications extend systemically, perpetuating discrimination based on
          age, race, culture, or sexual orientation. A real-world case is
          evident in Amazon's previous hiring system, where research identified
          the discriminatory nature of their ML model. This system downgraded
          resumes containing the term "Women," resulting in biased selections
          that disadvantaged female candidates in the top candidate pool.
        </p>
      </div>
    </section>

    <script type="module" src="/main.js"></script>
  </body>
</html>
