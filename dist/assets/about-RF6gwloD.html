<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>About Section</title>
  </head>
  <link rel="stylesheet" href="about.css" />
  <body>
    <nav>
      <a href="/">ClarityLens</a>
      <ul>
        <li><a href="/about">About</a></li>
        <li>
          <a href="https://observablehq.com/d/3d39e1f333def77c" target="_"
            >Demo</a
          >
        </li>
        <li>
          <a href="https://www.overleaf.com/read/mhdvcxdkcvhw#6d5ce0" target="_"
            >Paper</a
          >
        </li>
      </ul>
    </nav>
    <h1 class="about_title">Project Overview</h1>
    <div class="about">
      <p class="about_desc">
        In this project, we have developed a sophisticated and user-friendly
        web-based data visualization tool with interactive features that helps
        user uncover all stages of Machine Learninf pipeline. The tool will
        specifically focus on Machine Learning (ML) and Artificial intelligence
        (AI) datasets, offering users an intuitive platform to explore and
        analyze their data and check for biases. One primary objective was to
        empower users to identify and understand potential biases within the
        datasets, fostering transparency and accountability in machine learning
        processes. Through innovative visualization techniques, the tool will
        provide a dynamic environment for users to navigate through diverse
        datasets, gaining insights into their data, and find co-relation between
        features. The tool will also enable users understand all aspect of
        training and evaluating a model by authorizing complete control to users
        from training features, train-train split and interpretation of
        evaluation matrix for bias detection.
      </p>
      <p class="about_desc">
        Bias in the ML dataset indicates prejudices and unfair inaccuracies in
        the data that is used to train ML models. In simple terms, certain
        groups of a dataset are overweighted or overrepresented. This bias can
        have a significant impact on the fairness of ML models. Beyond the
        technical challenges of ML models producing inaccurate results, their
        implications extend systemically, perpetuating discrimination based on
        age, race, culture, or sexual orientation. A real-world case is evident
        in Amazon's flawed previous hiring system, where research identified the
        discriminatory nature of their ML model. This system downgraded resumes
        containing the term "Women," resulting in biased selections that
        disadvantaged female candidates in the top candidate pool.
      </p>
    </div>
    <script type="module" src="/about.js"></script>
  </body>
</html>
